{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0f582a4-df4e-498d-98ea-ca9e32937f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports and NeuralNetwork class definition\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, layer_sizes, learning_rate=0.01, seed=1):\n",
    "        \"\"\"\n",
    "        layer_sizes: list, e.g. [n_features, 16, 3] \n",
    "        \"\"\"\n",
    "        np.random.seed(seed)\n",
    "        self.learning_rate = learning_rate\n",
    "        self.sizes = layer_sizes\n",
    "        # He‐style initialization\n",
    "        self.W = [np.random.randn(a, b) * np.sqrt(2.0/a)\n",
    "                  for a, b in zip(layer_sizes[:-1], layer_sizes[1:])]\n",
    "        self.b = [np.zeros((1, b)) for b in layer_sizes[1:]]\n",
    "\n",
    "    def _relu(self, x):\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    def _relu_deriv(self, x):\n",
    "        return (x > 0).astype(float)\n",
    "\n",
    "    def _softmax(self, x):\n",
    "        ex = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "        return ex / np.sum(ex, axis=1, keepdims=True)\n",
    "\n",
    "    def _cross_entropy(self, y_true, y_pred):\n",
    "        m = y_true.shape[0]\n",
    "        p = np.clip(y_pred, 1e-12, 1 - 1e-12)\n",
    "        return -np.sum(y_true * np.log(p)) / m\n",
    "\n",
    "    def forward(self, X):\n",
    "        a = X\n",
    "        activations = [a]\n",
    "        zs = []\n",
    "        for W, b in zip(self.W[:-1], self.b[:-1]):\n",
    "            z = a.dot(W) + b\n",
    "            zs.append(z)\n",
    "            a = self._relu(z)\n",
    "            activations.append(a)\n",
    "        z = a.dot(self.W[-1]) + self.b[-1]\n",
    "        zs.append(z)\n",
    "        a = self._softmax(z)\n",
    "        activations.append(a)\n",
    "        return zs, activations\n",
    "\n",
    "    def backward(self, X, y_true, zs, activations):\n",
    "        grads_W = [np.zeros_like(W) for W in self.W]\n",
    "        grads_b = [np.zeros_like(b) for b in self.b]\n",
    "        m = X.shape[0]\n",
    "\n",
    "        # Output layer delta\n",
    "        delta = activations[-1] - y_true\n",
    "        grads_W[-1] = activations[-2].T.dot(delta) / m\n",
    "        grads_b[-1] = np.sum(delta, axis=0, keepdims=True) / m\n",
    "\n",
    "        # Backprop through hidden layers\n",
    "        for l in range(2, len(self.sizes)):\n",
    "            z = zs[-l]\n",
    "            delta = delta.dot(self.W[-l+1].T) * self._relu_deriv(z)\n",
    "            grads_W[-l] = activations[-l-1].T.dot(delta) / m\n",
    "            grads_b[-l] = np.sum(delta, axis=0, keepdims=True) / m\n",
    "\n",
    "        # Update parameters\n",
    "        for i in range(len(self.W)):\n",
    "            self.W[i] -= self.learning_rate * grads_W[i]\n",
    "            self.b[i] -= self.learning_rate * grads_b[i]\n",
    "\n",
    "    def train(self, X, y_true, epochs=500, print_every=100):\n",
    "        for epoch in range(1, epochs+1):\n",
    "            zs, activations = self.forward(X)\n",
    "            loss = self._cross_entropy(y_true, activations[-1])\n",
    "            self.backward(X, y_true, zs, activations)\n",
    "            if epoch % print_every == 0 or epoch == 1:\n",
    "                print(f\"Epoch {epoch}/{epochs}  Loss: {loss:.4f}\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        _, activations = self.forward(X)\n",
    "        return np.argmax(activations[-1], axis=1)\n",
    "\n",
    "    def accuracy(self, X, y_true_labels):\n",
    "        preds = self.predict(X)\n",
    "        return np.mean(preds == y_true_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b14b3691-b91b-401f-bd15-ad1f71b31f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Load & preprocess the Iris dataset\n",
    "\n",
    "# 1. Load data\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target.reshape(-1, 1)\n",
    "\n",
    "# 2. One-hot encode labels (fixed parameter name)\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "Y = encoder.fit_transform(y)\n",
    "\n",
    "# 3. Split into train/test\n",
    "X_train, X_test, Y_train, Y_test, y_train_lbl, y_test_lbl = train_test_split(\n",
    "    X, Y, y.ravel(), test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 4. Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test  = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c43c95e2-e842-402d-8bbf-11a7f2b92f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000  Loss: 1.6090\n",
      "Epoch 200/1000  Loss: 0.3149\n",
      "Epoch 400/1000  Loss: 0.2150\n",
      "Epoch 600/1000  Loss: 0.1550\n",
      "Epoch 800/1000  Loss: 0.1222\n",
      "Epoch 1000/1000  Loss: 0.1029\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Initialize and train the network\n",
    "\n",
    "# Architecture: 4 inputs → 8 hidden units → 3 outputs\n",
    "nn = NeuralNetwork([4, 8, 3], learning_rate=0.05)\n",
    "nn.train(X_train, Y_train, epochs=1000, print_every=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab6af519-228f-4b16-b928-440b6ee017b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set accuracy: 96.67%\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Evaluate on test set\n",
    "\n",
    "acc = nn.accuracy(X_test, y_test_lbl)\n",
    "print(f\"\\nTest set accuracy: {acc:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2066d42-a642-4331-88e9-90df17798d35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
